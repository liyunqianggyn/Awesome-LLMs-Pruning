# Awesome LLMs Pruning All-In-One [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

Integrating useful resources into one repository for large models pruning papers, including one sentence take-away summary, explanation notes such as paper's challenges,  blogs or videos, paper tags, source code links and venue.

Please feel free to [pull requests](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/pulls) or [open an issue](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/issues) to add papers.

:fire: Keep updating... 
Please star it if you find it helpful:)

## Table of Contents

- [Tags of Pruning](#tags-of-pruning)

- [2024 Venues](#2024)

- [2023 Venues](#2023)

[//]: # (- [2022 Venues]&#40;#2022&#41;)

### Tags of Pruning

We refer to our recent accepted ICCV paper [_differentiable transportation pruning_](https://arxiv.org/abs/2307.08483)   for summarizing these tags.
Click on the badge, such as [![Budget](https://img.shields.io/badge/Data-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md), will direct you to the corresponding explanation file. 


| [![Type](https://img.shields.io/badge/Type-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md) | [![Criteria](https://img.shields.io/badge/Criteria-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) | [![Budget](https://img.shields.io/badge/Budget-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) | [![Budget](https://img.shields.io/badge/Data-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md) | [![Type](https://img.shields.io/badge/Retrain-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md) | [![Type](https://img.shields.io/badge/Weight-yellow)](concepts/weight_update.md) |
|:-------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------:|
|                                                                        `Unstructured`                                                                         |                                                                     `Magnitude`                                                                      |                                                        `Sparsity e.g. layer or global`                                                        |                                                                `Data-free`                                                                |                                                                    `Without`                                                                    |                                     `Frozen`                                     |
|                                                                         `Structured`                                                                          |                                              `Taylor e.g.` [`Hessian`](https://arxiv.org/abs/1906.10771)                                              |                                                                    `FLOPs`                                                                    |                                                               `Calibration`                                                               |                                          `Efficient e.g.` [`LoRA`](concepts/details/LoRA.md)                                                    |                                     `Update`                                     |
|                                                                       `Semi-structured`                                                                       |                                                                       `Fisher`                                                                       |                                                                   `Latency`                                                                   |                                                                  `Small`                                                                  |                                                                   `Extensive`                                                                   |                                       `-`                                        |
|                                                                            `Other`                                                                            |                                                                     `Trainable`                                                                      |                                                                   `Energy`                                                                    |                                                                 `Medium`                                                                  |                                                                     `Other`                                                                     |                                       `-`                                        |
|                                                                             ` - `                                                                             |                                                                       `Other`                                                                        |                                                                    `Other`                                                                    |                                                                  `Large`                                                                  |                                                                       `-`                                                                       |                                       `-`                                        |


### 2024

| <div style="width: 150px">Title & Take-away </div>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <dir style="width: 100px"> Tags    </dir>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                                                                                                             <div style="width: 50px">Note </div>                                                                                                              |           <div style="width: 50px">Code </div>           |
|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------:|
| [![Star](https://img.shields.io/github/stars/locuslab/wanda.svg?style=social&label=Star)](https://github.com/locuslab/wanda) [![Publish](https://img.shields.io/badge/Submission-ICLR'24-blue)]() <br> [A Simple and Effective Pruning Approach for Large Language Models](https://arxiv.org/abs/2306.11695) <br> A pruning metric termed Wanda that considers both weight magnitudes and input activation norms to prune weights *per-output basis* instead of layer-wise, requiring no retraining or weight update.  A simplified version of [*SparseGPT*](https://arxiv.org/abs/2301.00774).                                                                 |                  [![Type](https://img.shields.io/badge/Type-Un/Semi--structured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br> [![Type](https://img.shields.io/badge/Criteria-Wanda-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity--layer-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Calibration-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Without-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md) <br> [![Type](https://img.shields.io/badge/Weight-Frozen-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md)                  | [Challenge](challenge/challenge.md/#wanda-simple-effective-pruning-approach-2024) <br/>[Blog](https://www.linkedin.com/pulse/efficient-model-pruning-large-language-models-wandas-ayoub-kirouane/) <br> [Reviews](https://openreview.net/forum?id=PxoFut3dWW) |       [PyTorch](https://github.com/locuslab/wanda)       |
| [![Star](https://img.shields.io/github/stars/LinkAnonymous/BESA.svg?style=social&label=Star)](https://github.com/LinkAnonymous/BESA) [![Publish](https://img.shields.io/badge/Submission-ICLR'24-blue)]() <br> [BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation](https://openreview.net/forum?id=gC6JTEU3jl)  <br> Adaptively allocate optimal sparsity ratio of each layer within a *transformer block* by minizming block-wise reconstruction error. To do so,  a parameter-efficient algorithm is developed with ony optimizing few learnable coefficients _e.g.,_ 100.  Pre-trained weights are frozen.          |     [![Type](https://img.shields.io/badge/Type-Unstructured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br> [![Type](https://img.shields.io/badge/Criteria-Wanda-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity--block-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Calibration-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Without-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md)                                  <br> [![Type](https://img.shields.io/badge/Weight-Frozen-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md)     |                [Challenge](challenge/challenge.md/#besa-blockwise-parameter-efficient-sparsity-allocation-2024) <br/>                                                                    [Reviews](https://openreview.net/forum?id=gC6JTEU3jl)                |     [PyTorch](https://github.com/LinkAnonymous/BESA)     |
| [![Star](https://img.shields.io/github/stars/princeton-nlp/LLM-Shearing.svg?style=social&label=Star)](https://github.com/princeton-nlp/LLM-Shearing) [![Publish](https://img.shields.io/badge/Submission-ICLR'24-blue)]()  <br>[Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning](https://arxiv.org/abs/2310.06694) <br>  In first stage, training-aware pruning learns masks  satisfying specified target by imposing regularization on ~0.4B tokens; then retrain on other ~5B tokens of _RedPajama_ dataset.   Dynamic batch loading method to update the composition of sampled data per mini-batch across different domains. |    [![Type](https://img.shields.io/badge/Type-Structured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br> [![Type](https://img.shields.io/badge/Criteria-Trainable-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity--mix-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Medium~50B-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Extensive-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md)                                  <br> [![Type](https://img.shields.io/badge/Weight-Update-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md)     |                                [Challenge](challenge/challenge.md/#sheared-llama-2024) <br/>                  [Blog](https://xiamengzhou.github.io/sheared-llama/) <br/> [Reviews](https://openreview.net/forum?id=09iOdaeOzp)                                | [PyTorch](https://github.com/princeton-nlp/LLM-Shearing) |
| [![Star](https://img.shields.io/github/stars/luuyin/OWL.svg?style=social&label=Star)](https://github.com/luuyin/OWL) [![Publish](https://img.shields.io/badge/Submission-ICLR'24-blue)]()  <br>[Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity](https://arxiv.org/abs/2310.05175)  <br>  Allocate non-uniform sparsity ratios across different layers guided by the principle that  a layer with higher proportion of [_outliers_](concepts/other_concepts.md/#Outliers-in-LLMs) should have a lower sparsity, then apply the more tailored layer-wise sparsity directly into Wanda and SparseGPT.          | [![Type](https://img.shields.io/badge/Type-Unstructured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br> [![Type](https://img.shields.io/badge/Criteria-Wanda/Hessian-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity--layer-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Calibration-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Without-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md)                                  <br> [![Type](https://img.shields.io/badge/Weight-Update-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md) |                                           [Challenge](challenge/challenge.md/#outlier-weighed-layerwise-sparsity-owl-2024) <br/>                             [Reviews](https://openreview.net/forum?id=pOBvr1PxFd)                                            |         [PyTorch](https://github.com/luuyin/OWL)         |
| [![Publish](https://img.shields.io/badge/Submission-ICLR'24-blue)]()  <br>[Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models](https://arxiv.org/abs/2310.05175)  <br>  Propose a new pruning criteria named [_RIA_](concepts/criteria.md) for LLMs. In [N:M](concepts/types.md/#semi-structured) structures, introduce a column permutation matrix for score matrix to maximize the total retained weight importance. No retraining.                                                                                                                                                                                           |      [![Type](https://img.shields.io/badge/Type-Un/Semi--structured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br> [![Type](https://img.shields.io/badge/Criteria-RIA-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Calibration-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Without-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md)                                  <br> [![Type](https://img.shields.io/badge/Weight-Frozen-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md)      |                                                               [Challenge](challenge/challenge.md/#plug-and-play-2024)<br/>               [Reviews](https://openreview.net/forum?id=Tr0lPx9woF)                                                                |                            -                             |

[//]: # (| [![Publish]&#40;https://img.shields.io/badge/Submission-ICLR'24-blue&#41;]&#40;&#41; <br> [Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models]&#40;https://openreview.net/forum?id=s2NjWfaYdZ&#41;  <br>                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |  [![Type]&#40;https://img.shields.io/badge/Type-Structured-blue&#41;]&#40;https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md&#41;  <br> [![Type]&#40;https://img.shields.io/badge/Criteria-Wanda-C2A4A6&#41;]&#40;https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md&#41; <br> [![Type]&#40;https://img.shields.io/badge/Budget-Sparsity--block-brown&#41;]&#40;https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md&#41; <br> [![Type]&#40;https://img.shields.io/badge/Data-Calibration-green&#41;]&#40;https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md&#41;   <br> [![Type]&#40;https://img.shields.io/badge/Retrain-Without-orange&#41;]&#40;https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md&#41;                                  <br> [![Type]&#40;https://img.shields.io/badge/Weight-Frozen-orange&#41;]&#40;https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md&#41;   |                                                         [Reviews]&#40;https://openreview.net/forum?id=s2NjWfaYdZ&#41;                                                          |                             -                              |)

[//]: # (Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs)
[//]: # (ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models)



### 2023

| <div style="width: 150px">Title & Take-away </div>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <dir style="width: 100px"> Tags    </dir>                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                                                         <div style="width: 50px">Note </div>                                                         |          <div style="width: 50px">Code </div>           |
|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------:|:-------------------------------------------------------:|
| [![Star](https://img.shields.io/github/stars/IST-DASLab/sparsegpt.svg?style=social&label=Star)](https://github.com/IST-DASLab/sparsegpt) [![Publish](https://img.shields.io/badge/Conference-ICML'23-blue)]() <br> [SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot](https://arxiv.org/abs/2301.00774) <br> Post-training method for pruning LLMs in one-shot without any retraining. Updating weights by solving a *layer-wise weight reconstruction* problem.                                                                                                                                                                                                                                |       [![Type](https://img.shields.io/badge/Type-Un/Semi--structured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)   <br> [![Type](https://img.shields.io/badge/Criteria-Hessian-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity--layer-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Calibration-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Without-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md) <br> [![Type](https://img.shields.io/badge/Weight-Update-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md)       | [Challenge](challenge/challenge.md/#sparsegpt-icml-2023)<br/> [Blog](https://neuralmagic.com/blog/sparsegpt-remove-100-billion-parameters-for-free/) | [PyTorch](https://github.com/IST-DASLab/sparsegpt)      |
| [![Star](https://img.shields.io/github/stars/horseee/LLM-Pruner.svg?style=social&label=Star)](https://github.com/horseee/LLM-Pruner) [![Publish](https://img.shields.io/badge/Conference-NeurIPS'23-blue)]() <br> [LLM-Pruner: On the Structural Pruning of Large Language Models](https://arxiv.org/abs/2305.11627) <br>  First discover all coupled structures following [*Depgraph*](https://arxiv.org/abs/2301.12900), then estimate grouped importance of coupled structure on calibration, then prune less important groups, and last finetune with efficient [*LoRA*](concepts/details/LoRA.md) on [Alpaca](https://github.com/gururise/AlpacaDataCleaned) dataset consists of  50K instruction-response pairs. |     [![Type](https://img.shields.io/badge/Type-Structured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br>  [![Type](https://img.shields.io/badge/Criteria-Hessian-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity--layer-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Small--50K-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Efficient--LoRA-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md)       <br> [![Type](https://img.shields.io/badge/Weight-Update-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md)     |                                              [Challenge](challenge/challenge.md/#llm-pruner-nips-2023)                                               |    [PyTorch](https://github.com/horseee/LLM-Pruner)     |
| [![Star](https://img.shields.io/github/stars/VITA-Group/essential_sparsity.svg?style=social&label=Star)](https://github.com/VITA-Group/essential_sparsity) [![Publish](https://img.shields.io/badge/Conference-NeurIPS'23-blue)]() <br>[The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter](https://arxiv.org/abs/2306.03805) <br>  Revisiting magnitude pruning and several interesting findings on pruning large scaled models. Most performances are reported with fine-tuned downstream tasks, except for that on modern-scale LLMs where _no retraining_ is performed.                                                                                                      | [![Type](https://img.shields.io/badge/Type-Unstructured-blue)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/types.md)  <br>  [![Type](https://img.shields.io/badge/Criteria-Magnitude-C2A4A6)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/criteria.md) <br> [![Type](https://img.shields.io/badge/Budget-Sparsity-brown)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/budget.md) <br> [![Type](https://img.shields.io/badge/Data-Small--tasks-green)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/data.md)   <br> [![Type](https://img.shields.io/badge/Retrain-Extensive/Without-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/finetune.md)       <br> [![Type](https://img.shields.io/badge/Weight-Update/Frozen-orange)](https://github.com/liyunqianggyn/LLMs-Pruning-All-In-One/blob/main/concepts/weight_update.md) |                                    [Challenge](challenge/challenge.md/#emergence-of-essential-sparsity-nips-2023)                                    |                                                         | [PyTorch](https://github.com/VITA-Group/essential_sparsity) |

[//]: # (Deja vu: Contextual sparsity for efficient llms at inference time. )

[//]: # (### 2022)

[//]: # (Parameter-Efficient Sparsity for Large Language Models Fine-Tuning, IJCAI)


## Related Repotories
   

[Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM)

[Awesome-LLM-Compression](https://github.com/HuangOwen/Awesome-LLM-Compression)


